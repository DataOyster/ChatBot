"""
CONNECTIQ RETRIEVER
===================
Production-grade semantic retrieval engine for RAG systems.

Consumes embeddings.json generated by embeddings.py,
performs similarity search, and returns top-k relevant chunks
for downstream chatbot / API usage.

Author: ConnectIQ Team
License: Proprietary - Commercial Use
"""

import json
import math
import heapq
from datetime import datetime, timezone
from typing import List, Dict, Tuple


class Retriever:
    """
    Semantic retriever for ConnectIQ RAG pipeline.

    Responsibilities:
    - Load vector embeddings
    - Compute similarity (cosine)
    - Perform top-k retrieval
    - Apply optional filters (page_type, quality)
    - Return deterministic, ranked results
    """

    def __init__(
        self,
        embeddings_file: str,
        top_k: int = 5,
        min_similarity: float = 0.2,
    ):
        self.embeddings_file = embeddings_file
        self.top_k = top_k
        self.min_similarity = min_similarity

        self.embeddings: List[Dict] = []
        self.vector_dim: int | None = None

        self.stats = {
            "embeddings_loaded": 0,
            "queries_executed": 0,
        }

        self._load_embeddings()

    # ===============================================================
    # LOADING
    # ===============================================================

    def _load_embeddings(self):
        with open(self.embeddings_file, "r", encoding="utf-8") as f:
            payload = json.load(f)

        if "embeddings" not in payload:
            raise ValueError("Invalid embeddings file: missing 'embeddings' key")

        self.embeddings = payload["embeddings"]
        self.stats["embeddings_loaded"] = len(self.embeddings)

        if self.embeddings:
            self.vector_dim = len(self.embeddings[0]["vector"])

    # ===============================================================
    # VECTOR MATH
    # ===============================================================

    @staticmethod
    def _dot(a: List[float], b: List[float]) -> float:
        return sum(x * y for x, y in zip(a, b))

    @staticmethod
    def _norm(v: List[float]) -> float:
        return math.sqrt(sum(x * x for x in v))

    def _cosine_similarity(self, a: List[float], b: List[float]) -> float:
        denom = self._norm(a) * self._norm(b)
        if denom == 0:
            return 0.0
        return self._dot(a, b) / denom

    # ===============================================================
    # RETRIEVAL
    # ===============================================================

    def query(
        self,
        query_embedding: List[float],
        filters: Dict | None = None,
    ) -> List[Dict]:
        """
        Execute semantic search.

        filters example:
        {
            "page_type": ["program", "speakers"],
            "quality": ["normal"]
        }
        """
        if self.vector_dim is None:
            return []

        if len(query_embedding) != self.vector_dim:
            raise ValueError("Query embedding dimension mismatch")

        self.stats["queries_executed"] += 1

        results: List[Tuple[float, Dict]] = []

        for record in self.embeddings:
            if filters and not self._passes_filters(record, filters):
                continue

            score = self._cosine_similarity(query_embedding, record["vector"])
            if score < self.min_similarity:
                continue

            results.append((score, record))

        # Top-k highest similarity
        top = heapq.nlargest(self.top_k, results, key=lambda x: x[0])

        return [
            {
                "chunk_id": r["chunk_id"],
                "parent_doc_id": r["parent_doc_id"],
                "url": r["url"],
                "page_type": r["page_type"],
                "title": r.get("title", ""),
                "content": r.get("content", ""),
                "quality": r.get("quality", "normal"),
                "similarity": round(score, 4),
            }
            for score, r in top
        ]

    def _passes_filters(self, record: Dict, filters: Dict) -> bool:
        for key, allowed_values in filters.items():
            if key not in record:
                return False
            if record[key] not in allowed_values:
                return False
        return True

    # ===============================================================
    # DEBUG / METRICS
    # ===============================================================

    def info(self) -> Dict:
        return {
            "embeddings_loaded": self.stats["embeddings_loaded"],
            "queries_executed": self.stats["queries_executed"],
            "vector_dim": self.vector_dim,
            "loaded_at": datetime.now(timezone.utc).isoformat(),
        }


# ===============================================================
# CLI (DEBUG / TESTING)
# ===============================================================

def main():
    import sys
    import random

    if len(sys.argv) < 2:
        print("""
Usage:
  python retriever.py embeddings.json

Note:
  This CLI is for validation only.
  In production, Retriever is called from the API / chatbot layer.
        """)
        sys.exit(1)

    embeddings_file = sys.argv[1]
    retriever = Retriever(embeddings_file=embeddings_file)

    # Dummy query vector (for sanity check)
    dummy_query = [random.random() for _ in range(retriever.vector_dim)]
    results = retriever.query(dummy_query)

    print("\nTop results (dummy query):")
    for r in results:
        print(f"- {r['similarity']} | {r['url']}")

    print("\nRetriever info:")
    print(retriever.info())


if __name__ == "__main__":
    main()